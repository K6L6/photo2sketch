{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show how to load pre-trained models and draw things with sketch-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import cPickle\n",
    "import codecs\n",
    "import collections\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from six.moves import xrange\n",
    "\n",
    "# libraries required for visualisation:\n",
    "from IPython.display import SVG, display\n",
    "import svgwrite # conda install -c omnia svgwrite=1.1.6\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set numpy output to something sensible\n",
    "np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Version: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "tf.logging.info(\"TensorFlow Version: %s\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sketch_rnn_train",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9bdff10808f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'./test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msketch_rnn_train\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named sketch_rnn_train"
     ]
    }
   ],
   "source": [
    "# import our command line tools\n",
    "import sys\n",
    "sys.path.insert(0, './test')\n",
    "from sketch_rnn_train import *\n",
    "from model import *\n",
    "from utils import *\n",
    "from rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# little function that displays vector images and saves them to .svg\n",
    "def draw_strokes(data, factor=0.2, svg_filename = '/tmp/sketch_rnn/svg/sample.svg'):\n",
    "  tf.gfile.MakeDirs(os.path.dirname(svg_filename))\n",
    "  min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
    "  dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
    "  dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
    "  dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
    "  lift_pen = 1\n",
    "  abs_x = 25 - min_x \n",
    "  abs_y = 25 - min_y\n",
    "  p = \"M%s,%s \" % (abs_x, abs_y)\n",
    "  command = \"m\"\n",
    "  for i in xrange(len(data)):\n",
    "    if (lift_pen == 1):\n",
    "      command = \"m\"\n",
    "    elif (command != \"l\"):\n",
    "      command = \"l\"\n",
    "    else:\n",
    "      command = \"\"\n",
    "    x = float(data[i,0])/factor\n",
    "    y = float(data[i,1])/factor\n",
    "    lift_pen = data[i, 2]\n",
    "    p += command+str(x)+\",\"+str(y)+\" \"\n",
    "  the_color = \"black\"\n",
    "  stroke_width = 1\n",
    "  dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
    "  dwg.save()\n",
    "  display(SVG(dwg.tostring()))\n",
    "\n",
    "# generate a 2D grid of many vector drawings\n",
    "def make_grid_svg(s_list, grid_space=10.0, grid_space_x=16.0):\n",
    "  def get_start_and_end(x):\n",
    "    x = np.array(x)\n",
    "    x = x[:, 0:2]\n",
    "    x_start = x[0]\n",
    "    x_end = x.sum(axis=0)\n",
    "    x = x.cumsum(axis=0)\n",
    "    x_max = x.max(axis=0)\n",
    "    x_min = x.min(axis=0)\n",
    "    center_loc = (x_max+x_min)*0.5\n",
    "    return x_start-center_loc, x_end\n",
    "  x_pos = 0.0\n",
    "  y_pos = 0.0\n",
    "  result = [[x_pos, y_pos, 1]]\n",
    "  for sample in s_list:\n",
    "    s = sample[0]\n",
    "    grid_loc = sample[1]\n",
    "    grid_y = grid_loc[0]*grid_space+grid_space*0.5\n",
    "    grid_x = grid_loc[1]*grid_space_x+grid_space_x*0.5\n",
    "    start_loc, delta_pos = get_start_and_end(s)\n",
    "\n",
    "    loc_x = start_loc[0]\n",
    "    loc_y = start_loc[1]\n",
    "    new_x_pos = grid_x+loc_x\n",
    "    new_y_pos = grid_y+loc_y\n",
    "    result.append([new_x_pos-x_pos, new_y_pos-y_pos, 0])\n",
    "\n",
    "    result += s.tolist()\n",
    "    result[-1][2] = 1\n",
    "    x_pos = new_x_pos+delta_pos[0]\n",
    "    y_pos = new_y_pos+delta_pos[1]\n",
    "  return np.array(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the path of the model you want to load, and also the path of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_dir = '/home/kelvin/OgataLab/magenta/magenta/models/sketch_rnn/sketchy_data/'\n",
    "data_dir = '/home/kelvin/OgataLab/magenta/magenta/models/sketch_rnn/sketchy_data/'\n",
    "models_root_dir = '/tmp/sketch_rnn/models'\n",
    "# model_dir = '/home/kelvin/OgataLab/magenta/magenta/models/sketch_rnn/airplane_c1_1'\n",
    "# model_dir = '/home/kelvin/OgataLab/magenta/magenta/models/sketch_rnn/data5'\n",
    "# model_dir = '/home/kelvin/OgataLab/magenta/magenta/models/sketch_rnn/layer_norm_1000/trained_data10'\n",
    "# model_dir = '/home/kelvin/OgataLab/magenta/magenta/models/sketch_rnn/lstm_1000/trained_data2'\n",
    "model_dir = '/tmp/sketch_rnn/models/aaron_sheep/layer_norm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download_pretrained_models(models_root_dir=models_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[train_set, valid_set, test_set, hps_model, eval_hps_model, sample_hps_model] = load_env(data_dir, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the sketch-rnn model here:\n",
    "reset_graph()\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define two convenience functions to encode a stroke into a latent vector, and decode from latent vector to stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(input_strokes):\n",
    "  strokes = to_big_strokes(input_strokes, max_len=100).tolist()\n",
    "  strokes.insert(0, [0, 0, 1, 0, 0])\n",
    "  seq_len = [len(input_strokes)]\n",
    "  print(\"in encode(): seq_len = {}\".format(seq_len))\n",
    "  draw_strokes(to_normal_strokes(np.array(strokes)))\n",
    "  return sess.run(eval_model.batch_z, feed_dict={eval_model.input_data: [strokes], eval_model.sequence_lengths: seq_len})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(z_input=None, draw_mode=True, temperature=0.1, factor=0.2):\n",
    "  z = None\n",
    "  if z_input is not None:\n",
    "    z = [z_input]\n",
    "  sample_strokes, m = sample(sess, sample_model, seq_len=eval_model.hps.max_seq_len, temperature=temperature, z=z)\n",
    "  strokes = to_normal_strokes(sample_strokes)\n",
    "  if draw_mode:\n",
    "    draw_strokes(strokes, factor)\n",
    "  return strokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample drawing from the test set, and render it to .svg\n",
    "# stroke = test_set.random_sample()\n",
    "stroke = train_set.random_sample()\n",
    "print(stroke.shape)\n",
    "draw_strokes(stroke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to encode the sample stroke into latent vector $z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = encode(stroke) #definition of latent vector z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = decode(z, temperature=0.1) # convert z back to drawing at temperature of 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create generated grid at various temperatures from 0.1 to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_list = []\n",
    "for i in range(10):\n",
    "  stroke_list.append([decode(z, draw_mode=False, temperature=0.1*i+0.1), [0, i]])\n",
    "stroke_grid = make_grid_svg(stroke_list)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Space Interpolation Example between $z_0$ and $z_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample drawing from the test set, and render it to .svg\n",
    "z0 = z\n",
    "_ = decode(z0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke = test_set.random_sample()\n",
    "z1 = encode(stroke)\n",
    "_ = decode(z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we interpolate between sheep $z_0$ and sheep $z_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_list = [] # interpolate spherically between z0 and z1\n",
    "N = 10\n",
    "for t in np.linspace(0, 1, N):\n",
    "  z_list.append(slerp(z0, z1, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for every latent vector in z_list, sample a vector image\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(z_list[i], draw_mode=False), [0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions)\n",
    "draw_strokes(stroke_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the Flamingo Model, and try Unconditional (Decoder-Only) Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/tmp/sketch_rnn/models/aaron_sheep/lstm_uncond'\n",
    "# sketchy_dir = '/home/kelvin/OgataLab/magenta/magenta/models/sketch_rnn/sketchy_data/' #sheep_ep03.npz\n",
    "[train_set, valid_set, test_set, hps_model, eval_hps_model, sample_hps_model] = load_env(data_dir, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[hps_model, eval_hps_model, sample_hps_model] = load_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# construct the sketch-rnn model here:\n",
    "reset_graph()\n",
    "model = Model(hps_model)\n",
    "eval_model = Model(eval_hps_model, reuse=True)\n",
    "sample_model = Model(sample_hps_model, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the weights from checkpoint into our model\n",
    "load_checkpoint(sess, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly unconditionally generate 10 examples\n",
    "N = 10\n",
    "reconstructions = []\n",
    "for i in range(N):\n",
    "  reconstructions.append([decode(temperature=0.5, draw_mode=False), [0, i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_grid = make_grid_svg(reconstructions)\n",
    "draw_strokes(stroke_grid)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
